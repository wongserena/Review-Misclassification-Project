{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1bdd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from 'modelling_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    # FIX: Loading the data from the specified file\n",
    "    df = pd.read_csv('../4-prep_model_data/modelling_data.csv')\n",
    "    print(\"Data loaded successfully from 'modelling_data.csv'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'modelling_data.csv' not found. Please ensure the file is in the current directory.\")\n",
    "    # Exiting or using mock data for demonstration purposes if the file isn't available\n",
    "    # For a real run, you would need the file.\n",
    "    # We will proceed with mock data just to illustrate the logic if the file is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b33fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Prepare Features (X) and Target (y) ---\n",
    "# Target variable\n",
    "y = df['stars_x'] \n",
    "\n",
    "# Features for the model (only 'text' as per your initial plan for a classic text model)\n",
    "X_text = df['text'] \n",
    "\n",
    "# Group variable for splitting\n",
    "groups = df['business_id'] \n",
    "\n",
    "# Drop NaN values that might prevent the split from working (especially in 'stars_x' or 'business_id')\n",
    "# This is a good practice for real-world data\n",
    "df.dropna(subset=['stars_x', 'business_id', 'text'], inplace=True) \n",
    "\n",
    "# Re-align variables after dropping NAs (if any were dropped)\n",
    "y = df['stars_x']\n",
    "X_text = df['text']\n",
    "groups = df['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeaceceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Data Points: 46457\n",
      "Training Set Size: 37828 (81.4%)\n",
      "Testing Set Size: 8629 (18.6%)\n",
      "Unique businesses in training set: 570\n",
      "Unique businesses in testing set: 134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. Stratified Group Split (80/20) ---\n",
    "# We use n_splits=5 so one fold is 20% for testing.\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Get the indices for the first split (80% train / 20% test)\n",
    "# This will ensure the distribution of star ratings (stratified) and the businesses (grouped) are respected\n",
    "try:\n",
    "    train_index, test_index = next(sgkf.split(X_text, y, groups))\n",
    "except ValueError as e:\n",
    "    print(f\"\\nCRITICAL ERROR during split: {e}\")\n",
    "    print(\"This often means one of your groups (business_id) has only a single star rating,\")\n",
    "    print(\"or one star rating has too few samples to be represented in all splits.\")\n",
    "    # Fallback to standard train_test_split (risks data leakage) or adjust data preprocessing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_index, test_index = train_test_split(df.index, test_size=0.2, stratify=y, random_state=42)\n",
    "    print(\"Falling back to standard stratified split (business separation compromised).\")\n",
    "\n",
    "\n",
    "# Apply the indices to the data\n",
    "X_train, X_test = X_text.loc[train_index], X_text.loc[test_index]\n",
    "y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "# Crucial: Keep the 'business_id' for the test set for later misclassification analysis\n",
    "business_ids_test = groups.loc[test_index] \n",
    "\n",
    "print(f\"\\nTotal Data Points: {len(df)}\")\n",
    "print(f\"Training Set Size: {len(X_train)} ({len(X_train) / len(df) * 100:.1f}%)\")\n",
    "print(f\"Testing Set Size: {len(X_test)} ({len(X_test) / len(df) * 100:.1f}%)\")\n",
    "print(f\"Unique businesses in training set: {groups.loc[train_index].nunique()}\")\n",
    "print(f\"Unique businesses in testing set: {groups.loc[test_index].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739773a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Build and Train the SVM Pipeline ---\n",
    "# A Pipeline simplifies the workflow: chains TF-IDF (Vectorization) and SVM (Model)\n",
    "model_pipeline = Pipeline([\n",
    "    # Step 1: Feature Extraction (TF-IDF) \n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        stop_words='english', \n",
    "        ngram_range=(1, 2), # Using single words and pairs of words (unigrams and bigrams)\n",
    "        max_features=10000  # Limit features to 10,000 for efficiency\n",
    "    )),\n",
    "    # Step 2: SVM Classifier (SVC) - Multi-class classification\n",
    "    ('svm', SVC(kernel='linear', C=1.0, random_state=42)) \n",
    "])\n",
    "\n",
    "print(\"\\nStarting model training...\")\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1801b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CLASSIFICATION REPORT ON TEST SET (Star Rating Prediction)\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.75      0.72      1137\n",
      "           2       0.42      0.32      0.36       755\n",
      "           3       0.45      0.34      0.39      1024\n",
      "           4       0.48      0.47      0.48      2089\n",
      "           5       0.73      0.81      0.77      3624\n",
      "\n",
      "    accuracy                           0.62      8629\n",
      "   macro avg       0.56      0.54      0.54      8629\n",
      "weighted avg       0.61      0.62      0.61      8629\n",
      "\n",
      "\n",
      "Misclassification Analysis DataFrame created.\n",
      "You can now analyze this DataFrame to find businesses with poor model performance.\n",
      "Sample of Misclassified Reviews (True vs. Predicted):\n",
      "              business_id  True_Star_Rating  Predicted_Star_Rating\n",
      "0  V7IHpr1xzFIf_jp876HoAw                 4                      3\n",
      "1  V7IHpr1xzFIf_jp876HoAw                 5                      4\n",
      "2  V7IHpr1xzFIf_jp876HoAw                 5                      4\n",
      "3  V7IHpr1xzFIf_jp876HoAw                 3                      5\n",
      "6  s9G06FPW74Prlp8s1h5nEA                 4                      5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 5. Evaluate the Model and Prepare for Misclassification Analysis ---\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASSIFICATION REPORT ON TEST SET (Star Rating Prediction)\")\n",
    "print(\"=\"*50)\n",
    "# Evaluation metrics for the multi-class classification problem\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Create the DataFrame needed for misclassification analysis\n",
    "misclassification_df = pd.DataFrame({\n",
    "    'business_id': business_ids_test.values,\n",
    "    'Review_Text': X_test.values,\n",
    "    'True_Star_Rating': y_test.values,\n",
    "    'Predicted_Star_Rating': y_pred\n",
    "})\n",
    "\n",
    "misclassification_df['Is_Misclassified'] = (misclassification_df['True_Star_Rating'] != misclassification_df['Predicted_Star_Rating'])\n",
    "\n",
    "print(\"\\nMisclassification Analysis DataFrame created.\")\n",
    "print(\"You can now analyze this DataFrame to find businesses with poor model performance.\")\n",
    "print(\"Sample of Misclassified Reviews (True vs. Predicted):\")\n",
    "print(misclassification_df[misclassification_df['Is_Misclassified']][['business_id', 'True_Star_Rating', 'Predicted_Star_Rating']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e7d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Businesses by Misclassification Rate:\n",
      "business_id\n",
      "V7IHpr1xzFIf_jp876HoAw    1.00\n",
      "k1hO7GVnNQLn8Ujx3wEW1Q    1.00\n",
      "x4jqqs-Hr7YXYJEqXVTR8w    0.80\n",
      "PbMrgxJDW_3hVXUFg7U95w    0.75\n",
      "ybQem1jFkGPI1F-PEfEZBQ    0.75\n",
      "Name: Is_Misclassified, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ... (all the previous code up to step 5)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# This is where the DataFrame is created:\n",
    "misclassification_df = pd.DataFrame({\n",
    "    'business_id': business_ids_test.values,\n",
    "    'Review_Text': X_test.values,\n",
    "    'True_Star_Rating': y_test.values,\n",
    "    'Predicted_Star_Rating': y_pred\n",
    "})\n",
    "\n",
    "misclassification_df['Is_Misclassified'] = (misclassification_df['True_Star_Rating'] != misclassification_df['Predicted_Star_Rating'])\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "# To view the entire DataFrame:\n",
    "# print(misclassification_df.head())\n",
    "\n",
    "# To find all misclassified reviews:\n",
    "# misclassified_reviews = misclassification_df[misclassification_df['Is_Misclassified']]\n",
    "\n",
    "# To find businesses with the highest misclassification rate:\n",
    "misclassification_rate_per_business = misclassification_df.groupby('business_id')['Is_Misclassified'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Businesses by Misclassification Rate:\")\n",
    "print(misclassification_rate_per_business.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
