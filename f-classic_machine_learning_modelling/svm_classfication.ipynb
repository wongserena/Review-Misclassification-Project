{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1bdd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from 'modelling_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../4-prep_model_data/modelling_data.csv')\n",
    "    print(\"Data loaded successfully from 'modelling_data.csv'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'modelling_data.csv' not found. Please ensure the file is in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b33fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "y = df['stars_x'] \n",
    "\n",
    "# Features for the model (only 'text' as per your initial plan for a classic text model)\n",
    "X_text = df['text'] \n",
    "\n",
    "groups = df['business_id'] \n",
    "\n",
    "# Drop NaN values that might prevent the split from working (especially in 'stars_x' or 'business_id')\n",
    "df.dropna(subset=['stars_x', 'business_id', 'text'], inplace=True) \n",
    "\n",
    "# Re-align variables after dropping NAs (if any were dropped)\n",
    "y = df['stars_x']\n",
    "X_text = df['text']\n",
    "groups = df['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaceceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Data Points: 46457\n",
      "Training Set Size: 37828 (81.4%)\n",
      "Testing Set Size: 8629 (18.6%)\n",
      "Unique businesses in training set: 570\n",
      "Unique businesses in testing set: 134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stratified Group Split (80/20)\n",
    "# We use n_splits=5 so one fold is 20% for testing.\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Get the indices for the first split (80% train / 20% test)\n",
    "try:\n",
    "    train_index, test_index = next(sgkf.split(X_text, y, groups))\n",
    "except ValueError as e:\n",
    "    print(f\"\\nCRITICAL ERROR during split: {e}\")\n",
    "    print(\"This often means one of your groups (business_id) has only a single star rating,\")\n",
    "    print(\"or one star rating has too few samples to be represented in all splits.\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_index, test_index = train_test_split(df.index, test_size=0.2, stratify=y, random_state=42)\n",
    "    print(\"Falling back to standard stratified split (business separation compromised).\")\n",
    "\n",
    "\n",
    "X_train, X_test = X_text.loc[train_index], X_text.loc[test_index]\n",
    "y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "business_ids_test = groups.loc[test_index] \n",
    "\n",
    "print(f\"\\nTotal Data Points: {len(df)}\")\n",
    "print(f\"Training Set Size: {len(X_train)} ({len(X_train) / len(df) * 100:.1f}%)\")\n",
    "print(f\"Testing Set Size: {len(X_test)} ({len(X_test) / len(df) * 100:.1f}%)\")\n",
    "print(f\"Unique businesses in training set: {groups.loc[train_index].nunique()}\")\n",
    "print(f\"Unique businesses in testing set: {groups.loc[test_index].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739773a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    }
   ],
   "source": [
    "# A Pipeline simplifies the workflow: chains TF-IDF (Vectorization) and SVM (Model)\n",
    "model_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        stop_words='english', \n",
    "        ngram_range=(1, 2), # Using single words and pairs of words (unigrams and bigrams)\n",
    "        max_features=10000  # Limit features to 10,000 for efficiency\n",
    "    )),\n",
    "    # SVM Classifier (SVC) - Multi-class classification\n",
    "    ('svm', SVC(kernel='linear', C=1.0, random_state=42)) \n",
    "])\n",
    "\n",
    "print(\"\\nStarting model training...\")\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1801b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CLASSIFICATION REPORT ON TEST SET (Star Rating Prediction)\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.75      0.72      1137\n",
      "           2       0.42      0.32      0.36       755\n",
      "           3       0.45      0.34      0.39      1024\n",
      "           4       0.48      0.47      0.48      2089\n",
      "           5       0.73      0.81      0.77      3624\n",
      "\n",
      "    accuracy                           0.62      8629\n",
      "   macro avg       0.56      0.54      0.54      8629\n",
      "weighted avg       0.61      0.62      0.61      8629\n",
      "\n",
      "\n",
      "Misclassification Analysis DataFrame created.\n",
      "You can now analyze this DataFrame to find businesses with poor model performance.\n",
      "Sample of Misclassified Reviews (True vs. Predicted):\n",
      "              business_id  True_Star_Rating  Predicted_Star_Rating\n",
      "0  V7IHpr1xzFIf_jp876HoAw                 4                      3\n",
      "1  V7IHpr1xzFIf_jp876HoAw                 5                      4\n",
      "2  V7IHpr1xzFIf_jp876HoAw                 5                      4\n",
      "3  V7IHpr1xzFIf_jp876HoAw                 3                      5\n",
      "6  s9G06FPW74Prlp8s1h5nEA                 4                      5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASSIFICATION REPORT ON TEST SET (Star Rating Prediction)\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "misclassification_df = pd.DataFrame({\n",
    "    'business_id': business_ids_test.values,\n",
    "    'Review_Text': X_test.values,\n",
    "    'True_Star_Rating': y_test.values,\n",
    "    'Predicted_Star_Rating': y_pred\n",
    "})\n",
    "\n",
    "misclassification_df['Is_Misclassified'] = (misclassification_df['True_Star_Rating'] != misclassification_df['Predicted_Star_Rating'])\n",
    "\n",
    "print(\"\\nMisclassification Analysis DataFrame created.\")\n",
    "print(\"You can now analyze this DataFrame to find businesses with poor model performance.\")\n",
    "print(\"Sample of Misclassified Reviews (True vs. Predicted):\")\n",
    "print(misclassification_df[misclassification_df['Is_Misclassified']][['business_id', 'True_Star_Rating', 'Predicted_Star_Rating']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e7d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Businesses by Misclassification Rate:\n",
      "business_id\n",
      "V7IHpr1xzFIf_jp876HoAw    1.00\n",
      "k1hO7GVnNQLn8Ujx3wEW1Q    1.00\n",
      "x4jqqs-Hr7YXYJEqXVTR8w    0.80\n",
      "PbMrgxJDW_3hVXUFg7U95w    0.75\n",
      "ybQem1jFkGPI1F-PEfEZBQ    0.75\n",
      "Name: Is_Misclassified, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "misclassification_df = pd.DataFrame({\n",
    "    'business_id': business_ids_test.values,\n",
    "    'Review_Text': X_test.values,\n",
    "    'True_Star_Rating': y_test.values,\n",
    "    'Predicted_Star_Rating': y_pred\n",
    "})\n",
    "\n",
    "misclassification_df['Is_Misclassified'] = (misclassification_df['True_Star_Rating'] != misclassification_df['Predicted_Star_Rating'])\n",
    "misclassification_rate_per_business = misclassification_df.groupby('business_id')['Is_Misclassified'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Businesses by Misclassification Rate:\")\n",
    "print(misclassification_rate_per_business.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
